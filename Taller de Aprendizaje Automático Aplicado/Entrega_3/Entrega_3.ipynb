{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ECEFF4\">\n",
    "\n",
    "# Entrega 3 - Conclusiones\n",
    "# \"Informalidad laboral en Chile: un análisis en base a la Encuesta Nacional de Empleo\"\n",
    "# Nombre: Nicolás Torres Hormazábal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ECEFF4\">\n",
    "\n",
    "### Este proyecto tiene como propósito desarrollar un modelo de ciencia de datos que explore y analice las características sociodemográficas, geográficas, educativas y otras variables que influyen en la probabilidad de que una persona opte o se vea obligada a trabajar en el sector informal. El objetivo es explicar el fenómeno de la informalidad y entender mejor a quienes forman parte de este sector, utilizando los resultados de la encuesta.\n",
    "### En esta entrega final, se presentará un modelo de redes neuronales con su respectiva optimización de hiperparametros usando optuna, así como correcciones respecto de la entrega pasada.\n",
    "### Finalmente, se presentarán las conclusiones y propuestas de mejora para el proyecto realizado, también para el diseño de la encuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tema y colores para nuestros gráficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import logging\n",
    "\n",
    "# Configurar logging para suprimir mensajes de advertencia de matplotlib\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "# Ruta al archivo de la fuente personalizada\n",
    "#CAMBIAR ESTO PARA QUE FUNCIONE CON VSC\n",
    "font_path = r'D:\\Google Drive\\Mi unidad\\TAAA\\Entrega_1\\FiraSans-Medium.ttf'  # Asegúrate de que esta ruta es correcta\n",
    "#font_path = r'/content/drive/MyDrive/TAAA/Entrega_1/FiraSans-Medium.ttf'\n",
    "prop = fm.FontProperties(fname=font_path)  # Cargar la fuente desde el archivo\n",
    "\n",
    "# Registrar la fuente personalizada en matplotlib\n",
    "fm.fontManager.addfont(font_path)\n",
    "plt.rcParams['font.family'] = prop.get_name()  # Usar Fira Sans como fuente predeterminada\n",
    "\n",
    "# Colores del tema Nord Aurora\n",
    "nord_aurora_colors = {\n",
    "    'background': '#ECEFF4',   # Fondo claro\n",
    "    'grid': '#4C566A',         # Color de la cuadrícula\n",
    "    'text': '#2e3440',         # Texto oscuro\n",
    "    'accent1': '#C3202F',      # Rojo intenso\n",
    "    'accent2': '#EBCB8B',      # Amarillo Aurora\n",
    "    'accent3': '#A3BE8C',      # Verde Aurora\n",
    "    'accent4': '#B48EAD',      # Morado Aurora\n",
    "}\n",
    "\n",
    "# Configurar matplotlib con el tema Nord Aurora y Fira Sans como predeterminada\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': nord_aurora_colors['background'],\n",
    "    'axes.facecolor': nord_aurora_colors['background'],\n",
    "    'axes.edgecolor': nord_aurora_colors['grid'],\n",
    "    'axes.labelcolor': nord_aurora_colors['text'],\n",
    "    'axes.titlecolor': nord_aurora_colors['text'],\n",
    "    'xtick.color': nord_aurora_colors['text'],\n",
    "    'ytick.color': nord_aurora_colors['text'],\n",
    "    'grid.color': nord_aurora_colors['grid'],\n",
    "    'grid.linewidth': 0,  # Desactivar la cuadrícula\n",
    "    'legend.frameon': False,\n",
    "    'legend.fontsize': 12,\n",
    "    'legend.labelcolor': nord_aurora_colors['text'],\n",
    "    'text.color': nord_aurora_colors['text'],\n",
    "    'axes.spines.top': False,   # Ocultar línea superior del eje\n",
    "    'axes.spines.right': False, # Ocultar línea derecha del eje\n",
    "    'axes.prop_cycle': plt.cycler(color=[\n",
    "        nord_aurora_colors['accent1'],\n",
    "        nord_aurora_colors['accent2'],\n",
    "        nord_aurora_colors['accent3'],\n",
    "        nord_aurora_colors['accent4']\n",
    "    ]),\n",
    "    'figure.figsize': (18, 9),\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "})\n",
    "\n",
    "# Configurar seaborn con el mismo estilo de fondo y colores Nord Aurora, y ocultar spines superior y derecha\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\",  # Utilizar cuadrícula blanca por defecto\n",
    "    rc={\n",
    "        \"axes.facecolor\": nord_aurora_colors['background'],\n",
    "        \"figure.facecolor\": nord_aurora_colors['background'],\n",
    "        \"axes.edgecolor\": nord_aurora_colors['grid'],\n",
    "        \"xtick.color\": nord_aurora_colors['text'],\n",
    "        \"ytick.color\": nord_aurora_colors['text'],\n",
    "        \"axes.labelcolor\": nord_aurora_colors['text'],\n",
    "        \"axes.titlecolor\": nord_aurora_colors['text'],\n",
    "        \"axes.spines.top\": False,    # Ocultar línea superior del eje\n",
    "        \"axes.spines.right\": False,  # Ocultar línea derecha del eje\n",
    "        \"font.family\": prop.get_name(),   # Establecer Fira Sans como fuente predeterminada\n",
    "    }\n",
    ")\n",
    "\n",
    "# Definir una paleta personalizada para seaborn usando los acentos de Nord Aurora\n",
    "nord_palette = [nord_aurora_colors['accent1'], nord_aurora_colors['accent2'], nord_aurora_colors['accent3'], nord_aurora_colors['accent4']]\n",
    "sns.set_palette(nord_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colores para ocupados\n",
    "palette = {\n",
    "    'Ocupado Formal': '#263252',  # Azul intenso para Ocupado Formal\n",
    "    'Ocupado Informal': '#fc4b08' # Naranja\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para que muestre los gráficos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ILibrerías\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "#ignorar todos los warnings (esto lo hicimos una vez ya realizamos todo el procesamiento y graficos)\n",
    "#es solo por estética\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "#con esto mostramos todas las columnas de los dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = pd.read_csv(r'D:\\Google Drive\\Mi unidad\\TAAA\\Entrega_3\\df_imputed.csv', sep=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>mes_encuesta</th>\n",
       "      <th>r_p_c</th>\n",
       "      <th>tipo</th>\n",
       "      <th>sexo</th>\n",
       "      <th>cine</th>\n",
       "      <th>proveedor</th>\n",
       "      <th>edad</th>\n",
       "      <th>nacionalidad</th>\n",
       "      <th>estudia_actual</th>\n",
       "      <th>orig1</th>\n",
       "      <th>mig1</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b5</th>\n",
       "      <th>b7a_1</th>\n",
       "      <th>b7a_2</th>\n",
       "      <th>b7a_3</th>\n",
       "      <th>b7b_2</th>\n",
       "      <th>b7b_3</th>\n",
       "      <th>b8</th>\n",
       "      <th>b12</th>\n",
       "      <th>b11_proxy</th>\n",
       "      <th>b14_rev4cl_caenes</th>\n",
       "      <th>i1</th>\n",
       "      <th>i2</th>\n",
       "      <th>i3</th>\n",
       "      <th>ocup_honorarios</th>\n",
       "      <th>plataformas_digitales</th>\n",
       "      <th>turno</th>\n",
       "      <th>habituales</th>\n",
       "      <th>ocup_form</th>\n",
       "      <th>r_p_rev4cl_caenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16203</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.343912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.121710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.767100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14201</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.343912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.269845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  mes_encuesta  r_p_c  tipo  sexo  cine  proveedor  edad  \\\n",
       "0      16             1  16203     1     2     6          0    24   \n",
       "1       5             1   5101     1     1     8          1    58   \n",
       "2       3             1   3201     1     1     4          1    61   \n",
       "3      14             1  14201     3     2     5          0    49   \n",
       "4       9             1   9102     1     2     7          0    49   \n",
       "\n",
       "   nacionalidad  estudia_actual  orig1  mig1   a1    a2   a3   b1   b2    b5  \\\n",
       "0           152               2      2     1  1.0  99.0  1.0  5.0  2.0   3.0   \n",
       "1           152               2      2     1  1.0  99.0  1.0  2.0  1.0  99.0   \n",
       "2           152               2      2     1  1.0  99.0  1.0  7.0  2.0   2.0   \n",
       "3           152               2      2     1  1.0  99.0  1.0  5.0  2.0   2.0   \n",
       "4           152               2      2     1  1.0  99.0  1.0  3.0  2.0   1.0   \n",
       "\n",
       "   b7a_1  b7a_2  b7a_3  b7b_2  b7b_3    b8   b12  b11_proxy  \\\n",
       "0    1.0    1.0    1.0    1.0    2.0   1.0  99.0        1.0   \n",
       "1   99.0   99.0   99.0   99.0   99.0  99.0  99.0        2.0   \n",
       "2    2.0    2.0    2.0    2.0    2.0   2.0   1.0        1.0   \n",
       "3    1.0    1.0    1.0    1.0    1.0   1.0   2.0        1.0   \n",
       "4    1.0    1.0    1.0    1.0    1.0   1.0   1.0        1.0   \n",
       "\n",
       "   b14_rev4cl_caenes    i1    i2    i3  ocup_honorarios  \\\n",
       "0               20.0  99.0  99.0  99.0              2.0   \n",
       "1               13.0  99.0  99.0  99.0              2.0   \n",
       "2                3.0   1.0   1.0   1.0              2.0   \n",
       "3               16.0   1.0   1.0   1.0              2.0   \n",
       "4               16.0   1.0   1.0   1.0              2.0   \n",
       "\n",
       "   plataformas_digitales  turno  habituales  ocup_form  r_p_rev4cl_caenes  \n",
       "0                    2.0    2.0    0.343912        0.0               20.0  \n",
       "1                    2.0    2.0    0.121710        0.0               13.0  \n",
       "2                    2.0    2.0   -0.767100        1.0                3.0  \n",
       "3                    2.0    2.0    0.343912        0.0                9.0  \n",
       "4                    2.0    2.0    0.269845        0.0               16.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X = df_imputed.drop(columns=['ocup_form'])\n",
    "y = df_imputed['ocup_form']\n",
    "# Entrenamiento = 70%\n",
    "# Prueba = 30%\n",
    "# Estratificado en y, ya que está desbalanceado\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152105 entries, 0 to 152104\n",
      "Data columns (total 36 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   region                 152105 non-null  int64  \n",
      " 1   mes_encuesta           152105 non-null  int64  \n",
      " 2   r_p_c                  152105 non-null  int64  \n",
      " 3   tipo                   152105 non-null  int64  \n",
      " 4   sexo                   152105 non-null  int64  \n",
      " 5   cine                   152105 non-null  int64  \n",
      " 6   proveedor              152105 non-null  int64  \n",
      " 7   edad                   152105 non-null  int64  \n",
      " 8   nacionalidad           152105 non-null  int64  \n",
      " 9   estudia_actual         152105 non-null  int64  \n",
      " 10  orig1                  152105 non-null  int64  \n",
      " 11  mig1                   152105 non-null  int64  \n",
      " 12  a1                     152105 non-null  float64\n",
      " 13  a2                     152105 non-null  float64\n",
      " 14  a3                     152105 non-null  float64\n",
      " 15  b1                     152105 non-null  float64\n",
      " 16  b2                     152105 non-null  float64\n",
      " 17  b5                     152105 non-null  float64\n",
      " 18  b7a_1                  152105 non-null  float64\n",
      " 19  b7a_2                  152105 non-null  float64\n",
      " 20  b7a_3                  152105 non-null  float64\n",
      " 21  b7b_2                  152105 non-null  float64\n",
      " 22  b7b_3                  152105 non-null  float64\n",
      " 23  b8                     152105 non-null  float64\n",
      " 24  b12                    152105 non-null  float64\n",
      " 25  b11_proxy              152105 non-null  float64\n",
      " 26  b14_rev4cl_caenes      152105 non-null  float64\n",
      " 27  i1                     152105 non-null  float64\n",
      " 28  i2                     152105 non-null  float64\n",
      " 29  i3                     152105 non-null  float64\n",
      " 30  ocup_honorarios        152105 non-null  float64\n",
      " 31  plataformas_digitales  152105 non-null  float64\n",
      " 32  turno                  152105 non-null  float64\n",
      " 33  habituales             152105 non-null  float64\n",
      " 34  ocup_form              152105 non-null  float64\n",
      " 35  r_p_rev4cl_caenes      152105 non-null  float64\n",
      "dtypes: float64(24), int64(12)\n",
      "memory usage: 41.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Separate the column that shouldn't be encoded\n",
    "X_non_categorical = df_imputed[['habituales']]\n",
    "\n",
    "# Select all columns except 'habituales' for one-hot encoding\n",
    "categorical_columns = [col for col in df_imputed.columns if col != 'habituales']\n",
    "X_categorical = df_imputed[categorical_columns]\n",
    "\n",
    "# Apply one-hot encoding with sparse matrix using the corrected argument\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=True, drop='first')  # Corrected 'sparse' to 'sparse_output'\n",
    "X_categorical_encoded_sparse = one_hot_encoder.fit_transform(X_categorical)\n",
    "\n",
    "# Convert the 'habituales' column to a sparse matrix for consistency\n",
    "X_non_categorical_sparse = X_non_categorical.to_numpy()\n",
    "\n",
    "# Combine the sparse matrices\n",
    "X_final_sparse = hstack([X_non_categorical_sparse, X_categorical_encoded_sparse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:09:48,120] A new study created in memory with name: no-name-6ad5f5c7-65e4-42ca-9118-5ec5537e3558\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:16:21,463] Trial 0 finished with value: -0.9999619178186526 and parameters: {'num_units': 40, 'learning_rate': 0.0015503922405725684, 'dropout_rate': 0.4352430071755233, 'batch_size': 16, 'epochs': 44}. Best is trial 0 with value: -0.9999619178186526.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:18:31,090] Trial 1 finished with value: -0.9999238327366897 and parameters: {'num_units': 48, 'learning_rate': 0.004578004638964526, 'dropout_rate': 0.05645178572387638, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: -0.9999619178186526.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:20:12,561] Trial 2 finished with value: -1.0 and parameters: {'num_units': 28, 'learning_rate': 0.006358720879026974, 'dropout_rate': 0.4908199591525962, 'batch_size': 32, 'epochs': 21}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:23:50,801] Trial 3 finished with value: -1.0 and parameters: {'num_units': 12, 'learning_rate': 0.0018222307287853704, 'dropout_rate': 0.42713620552241366, 'batch_size': 32, 'epochs': 49}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:26:53,148] Trial 4 finished with value: -0.9999619178186526 and parameters: {'num_units': 20, 'learning_rate': 0.001238577762828095, 'dropout_rate': 0.2848202368198418, 'batch_size': 16, 'epochs': 21}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:29:10,079] Trial 5 finished with value: -0.9999238385377 and parameters: {'num_units': 60, 'learning_rate': 0.000326783659760162, 'dropout_rate': 0.17243097337774088, 'batch_size': 64, 'epochs': 46}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:35:49,143] Trial 6 finished with value: -0.9999238385377 and parameters: {'num_units': 20, 'learning_rate': 0.0002122098450269737, 'dropout_rate': 0.45639561253918853, 'batch_size': 16, 'epochs': 45}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:37:03,377] Trial 7 finished with value: -0.9999619178186526 and parameters: {'num_units': 20, 'learning_rate': 0.0003083441503502718, 'dropout_rate': 0.43978290592233005, 'batch_size': 64, 'epochs': 28}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:38:10,526] Trial 8 finished with value: -0.9999619178186526 and parameters: {'num_units': 8, 'learning_rate': 0.00020351176771513774, 'dropout_rate': 0.4471957942695193, 'batch_size': 64, 'epochs': 28}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:38:50,042] Trial 9 finished with value: -0.9998095600837935 and parameters: {'num_units': 12, 'learning_rate': 0.0023424770244325818, 'dropout_rate': 0.20555052862410172, 'batch_size': 32, 'epochs': 8}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:40:02,076] Trial 10 finished with value: -0.9999619178186526 and parameters: {'num_units': 36, 'learning_rate': 0.009327824383419565, 'dropout_rate': 0.31826741660761526, 'batch_size': 32, 'epochs': 14}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:42:56,403] Trial 11 finished with value: -0.9999619178186526 and parameters: {'num_units': 28, 'learning_rate': 0.00375003178457329, 'dropout_rate': 0.3550165858644073, 'batch_size': 32, 'epochs': 37}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:45:45,231] Trial 12 finished with value: -0.9999238327366897 and parameters: {'num_units': 4, 'learning_rate': 0.0006190866096189092, 'dropout_rate': 0.4870690201510216, 'batch_size': 32, 'epochs': 35}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:47:17,738] Trial 13 finished with value: -1.0 and parameters: {'num_units': 28, 'learning_rate': 0.009708298108800853, 'dropout_rate': 0.36613474306918403, 'batch_size': 32, 'epochs': 19}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:50:14,128] Trial 14 finished with value: -0.9999619178186526 and parameters: {'num_units': 48, 'learning_rate': 0.004535511026727191, 'dropout_rate': 0.37569335506398027, 'batch_size': 32, 'epochs': 35}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:52:08,726] Trial 15 finished with value: -0.9999619178186526 and parameters: {'num_units': 12, 'learning_rate': 0.0005918663379075565, 'dropout_rate': 0.11373001917328729, 'batch_size': 32, 'epochs': 21}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:52:46,342] Trial 16 finished with value: -0.9999619178186526 and parameters: {'num_units': 28, 'learning_rate': 0.0023371868182299493, 'dropout_rate': 0.4944407035416798, 'batch_size': 32, 'epochs': 6}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:54:02,897] Trial 17 finished with value: -0.9999619178186526 and parameters: {'num_units': 16, 'learning_rate': 0.0007580820079815748, 'dropout_rate': 0.3915487529623783, 'batch_size': 32, 'epochs': 14}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 13:56:54,249] Trial 18 finished with value: -0.999885753455958 and parameters: {'num_units': 4, 'learning_rate': 0.00011734227121926448, 'dropout_rate': 0.26809988176070265, 'batch_size': 32, 'epochs': 31}. Best is trial 2 with value: -1.0.\n",
      "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 14:04:10,475] Trial 19 finished with value: -0.9999619178186526 and parameters: {'num_units': 64, 'learning_rate': 0.006942466148802547, 'dropout_rate': 0.20888328356208974, 'batch_size': 16, 'epochs': 40}. Best is trial 2 with value: -1.0.\n",
      "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'num_units': 28, 'learning_rate': 0.006358720879026974, 'dropout_rate': 0.4908199591525962, 'batch_size': 32, 'epochs': 21}\n",
      "Epoch 1/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.0823\n",
      "Epoch 2/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0099\n",
      "Epoch 3/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0054\n",
      "Epoch 4/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0050\n",
      "Epoch 5/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0027\n",
      "Epoch 6/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0031\n",
      "Epoch 7/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0026\n",
      "Epoch 8/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0035\n",
      "Epoch 9/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 10/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0034\n",
      "Epoch 11/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 12/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0022\n",
      "Epoch 13/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.1396e-04\n",
      "Epoch 14/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019\n",
      "Epoch 15/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0019\n",
      "Epoch 16/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 8.5804e-04\n",
      "Epoch 17/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0014\n",
      "Epoch 18/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 8.1631e-04\n",
      "Epoch 19/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 20/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0014\n",
      "Epoch 21/21\n",
      "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 8.1362e-04\n",
      "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\n",
      "Final Test F1 Score: 1.0\n",
      "Final Test Recall: 1.0\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     32503\n",
      "         1.0       1.00      1.00      1.00     13129\n",
      "\n",
      "    accuracy                           1.00     45632\n",
      "   macro avg       1.00      1.00      1.00     45632\n",
      "weighted avg       1.00      1.00      1.00     45632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, recall_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert sparse matrix to dense if necessary\n",
    "X_encoded = X_final_sparse  # From previous encoding step\n",
    "y = df_imputed['ocup_form']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Normalize the data (sparse compatibility)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the objective function for Optuna optimization\n",
    "def objective(trial):\n",
    "    # Hyperparameter search space\n",
    "    num_units = trial.suggest_int('num_units', 4, 64, step=4)  # Number of neurons\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)  # Dropout rate\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])  # Batch size\n",
    "    epochs = trial.suggest_int('epochs', 5, 50)  # Number of epochs\n",
    "\n",
    "    # Define the model with the current trial's hyperparameters\n",
    "    model = Sequential([\n",
    "        Dense(num_units, input_dim=X_train.shape[1], activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Predict and evaluate using F1 Score and Recall\n",
    "    y_pred_prob = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Return a metric to minimize (negative F1 Score to maximize it)\n",
    "    return -f1\n",
    "\n",
    "# Create the study and optimize hyperparameters\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_model = Sequential([\n",
    "    Dense(best_params['num_units'], input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n",
    "# Evaluate the final model\n",
    "y_pred_prob = best_model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "final_f1 = f1_score(y_test, y_pred)\n",
    "final_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Print final metrics\n",
    "print(f\"\\nFinal Test F1 Score: {final_f1}\")\n",
    "print(f\"Final Test Recall: {final_recall}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna se demoró 56 minutos y obtuvo\n",
    "\n",
    "# Best Hyperparameters: {'num_units': 28, 'learning_rate': 0.006358720879026974, 'dropout_rate': 0.4908199591525962, 'batch_size': 32, 'epochs': 21}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[I 2025-01-07 13:09:48,120] A new study created in memory with name: no-name-6ad5f5c7-65e4-42ca-9118-5ec5537e3558\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:16:21,463] Trial 0 finished with value: -0.9999619178186526 and parameters: {'num_units': 40, 'learning_rate': 0.0015503922405725684, 'dropout_rate': 0.4352430071755233, 'batch_size': 16, 'epochs': 44}. Best is trial 0 with value: -0.9999619178186526.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:18:31,090] Trial 1 finished with value: -0.9999238327366897 and parameters: {'num_units': 48, 'learning_rate': 0.004578004638964526, 'dropout_rate': 0.05645178572387638, 'batch_size': 64, 'epochs': 49}. Best is trial 0 with value: -0.9999619178186526.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:20:12,561] Trial 2 finished with value: -1.0 and parameters: {'num_units': 28, 'learning_rate': 0.006358720879026974, 'dropout_rate': 0.4908199591525962, 'batch_size': 32, 'epochs': 21}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:23:50,801] Trial 3 finished with value: -1.0 and parameters: {'num_units': 12, 'learning_rate': 0.0018222307287853704, 'dropout_rate': 0.42713620552241366, 'batch_size': 32, 'epochs': 49}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:26:53,148] Trial 4 finished with value: -0.9999619178186526 and parameters: {'num_units': 20, 'learning_rate': 0.001238577762828095, 'dropout_rate': 0.2848202368198418, 'batch_size': 16, 'epochs': 21}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:29:10,079] Trial 5 finished with value: -0.9999238385377 and parameters: {'num_units': 60, 'learning_rate': 0.000326783659760162, 'dropout_rate': 0.17243097337774088, 'batch_size': 64, 'epochs': 46}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:35:49,143] Trial 6 finished with value: -0.9999238385377 and parameters: {'num_units': 20, 'learning_rate': 0.0002122098450269737, 'dropout_rate': 0.45639561253918853, 'batch_size': 16, 'epochs': 45}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:37:03,377] Trial 7 finished with value: -0.9999619178186526 and parameters: {'num_units': 20, 'learning_rate': 0.0003083441503502718, 'dropout_rate': 0.43978290592233005, 'batch_size': 64, 'epochs': 28}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:38:10,526] Trial 8 finished with value: -0.9999619178186526 and parameters: {'num_units': 8, 'learning_rate': 0.00020351176771513774, 'dropout_rate': 0.4471957942695193, 'batch_size': 64, 'epochs': 28}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:38:50,042] Trial 9 finished with value: -0.9998095600837935 and parameters: {'num_units': 12, 'learning_rate': 0.0023424770244325818, 'dropout_rate': 0.20555052862410172, 'batch_size': 32, 'epochs': 8}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:40:02,076] Trial 10 finished with value: -0.9999619178186526 and parameters: {'num_units': 36, 'learning_rate': 0.009327824383419565, 'dropout_rate': 0.31826741660761526, 'batch_size': 32, 'epochs': 14}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:42:56,403] Trial 11 finished with value: -0.9999619178186526 and parameters: {'num_units': 28, 'learning_rate': 0.00375003178457329, 'dropout_rate': 0.3550165858644073, 'batch_size': 32, 'epochs': 37}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:45:45,231] Trial 12 finished with value: -0.9999238327366897 and parameters: {'num_units': 4, 'learning_rate': 0.0006190866096189092, 'dropout_rate': 0.4870690201510216, 'batch_size': 32, 'epochs': 35}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:47:17,738] Trial 13 finished with value: -1.0 and parameters: {'num_units': 28, 'learning_rate': 0.009708298108800853, 'dropout_rate': 0.36613474306918403, 'batch_size': 32, 'epochs': 19}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:50:14,128] Trial 14 finished with value: -0.9999619178186526 and parameters: {'num_units': 48, 'learning_rate': 0.004535511026727191, 'dropout_rate': 0.37569335506398027, 'batch_size': 32, 'epochs': 35}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:52:08,726] Trial 15 finished with value: -0.9999619178186526 and parameters: {'num_units': 12, 'learning_rate': 0.0005918663379075565, 'dropout_rate': 0.11373001917328729, 'batch_size': 32, 'epochs': 21}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:52:46,342] Trial 16 finished with value: -0.9999619178186526 and parameters: {'num_units': 28, 'learning_rate': 0.0023371868182299493, 'dropout_rate': 0.4944407035416798, 'batch_size': 32, 'epochs': 6}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
    "[I 2025-01-07 13:54:02,897] Trial 17 finished with value: -0.9999619178186526 and parameters: {'num_units': 16, 'learning_rate': 0.0007580820079815748, 'dropout_rate': 0.3915487529623783, 'batch_size': 32, 'epochs': 14}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
    "[I 2025-01-07 13:56:54,249] Trial 18 finished with value: -0.999885753455958 and parameters: {'num_units': 4, 'learning_rate': 0.00011734227121926448, 'dropout_rate': 0.26809988176070265, 'batch_size': 32, 'epochs': 31}. Best is trial 2 with value: -1.0.\n",
    "C:\\Users\\nicot\\AppData\\Local\\Temp\\ipykernel_3208\\2417410773.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
    "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)  # Learning rate\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
    "[I 2025-01-07 14:04:10,475] Trial 19 finished with value: -0.9999619178186526 and parameters: {'num_units': 64, 'learning_rate': 0.006942466148802547, 'dropout_rate': 0.20888328356208974, 'batch_size': 16, 'epochs': 40}. Best is trial 2 with value: -1.0.\n",
    "c:\\Users\\nicot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "Best Hyperparameters: {'num_units': 28, 'learning_rate': 0.006358720879026974, 'dropout_rate': 0.4908199591525962, 'batch_size': 32, 'epochs': 21}\n",
    "Epoch 1/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.0823\n",
    "Epoch 2/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0099\n",
    "Epoch 3/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0054\n",
    "Epoch 4/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0050\n",
    "Epoch 5/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0027\n",
    "Epoch 6/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0031\n",
    "Epoch 7/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0026\n",
    "Epoch 8/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0035\n",
    "Epoch 9/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0016\n",
    "Epoch 10/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0034\n",
    "Epoch 11/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011\n",
    "Epoch 12/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0022\n",
    "Epoch 13/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.1396e-04\n",
    "Epoch 14/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019\n",
    "Epoch 15/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0019\n",
    "Epoch 16/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 8.5804e-04\n",
    "Epoch 17/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0014\n",
    "Epoch 18/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 8.1631e-04\n",
    "Epoch 19/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010\n",
    "Epoch 20/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0014\n",
    "Epoch 21/21\n",
    "\u001b[1m3328/3328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 8.1362e-04\n",
    "\u001b[1m1426/1426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
    "\n",
    "Final Test F1 Score: 1.0\n",
    "Final Test Recall: 1.0\n",
    "\n",
    "Final Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     32503\n",
    "         1.0       1.00      1.00      1.00     13129\n",
    "\n",
    "    accuracy                           1.00     45632\n",
    "   macro avg       1.00      1.00      1.00     45632\n",
    "weighted avg       1.00      1.00      1.00     45632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test F1 Score: 1.0\n",
      "Final Test Recall: 1.0\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     32503\n",
      "         1.0       1.00      1.00      1.00     13129\n",
      "\n",
      "    accuracy                           1.00     45632\n",
      "   macro avg       1.00      1.00      1.00     45632\n",
      "weighted avg       1.00      1.00      1.00     45632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print final metrics\n",
    "print(f\"\\nFinal Test F1 Score: {final_f1}\")\n",
    "print(f\"Final Test Recall: {final_recall}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
